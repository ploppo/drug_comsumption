{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "judicial-cologne",
   "metadata": {},
   "source": [
    "# Fisher Discriminant Analysis\n",
    "\n",
    "In questo laboratorio studieremo l'implementazione della Fisher Discriminant Analysis (FDA), in particolare nella sua forma generalizzata a più classi (Multiple Discriminant Analysis - MDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worst-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** NOTA BENE! *****\n",
    "# perché %matplotlib widget funzioni, installare nell'ambiente virtuale \n",
    "# il pacchetto ipympl con il comando:\n",
    "# pip install ipympl\n",
    "#\n",
    "# ATTENZIONE: perché funzioni è necessario chiudere e rilanciare jupyter-lab\n",
    "#\n",
    "# STILE DI VISUALIZZAZIONE PLOT FATTI CON MATPLOTLIB\n",
    "%matplotlib widget\n",
    "#\n",
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display\n",
    "from FisherDA import MultipleFisherDiscriminantAnalysis as MDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-austria",
   "metadata": {},
   "source": [
    "## Importazione Dataset digits\n",
    "\n",
    "Importiamo il dataset \"digits\" di scikit-learn come visto nei laboratori per la PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legendary-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "digits_dataset = datasets.load_digits(as_frame=True)\n",
    "\n",
    "print(digits_dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "formed-plaza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166a3a066a9a4ed4991afd321ee8fcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12bc03b8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizziamo un numero a caso (analogamente a quanto fatto per l'esercizio sulle eigenfaces).\n",
    "\n",
    "i_rand = np.random.choice(digits_dataset['data'].shape[0], 1, replace=False)\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(digits_dataset['images'][int(i_rand)], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-duncan",
   "metadata": {},
   "source": [
    "## MDA e PCA a Confronto.\n",
    "\n",
    "Effettuiamo una riduzione di dimensionalità del dataset sia rispetto la MDA che la PCA. Visualizziamo poi i risultati per notare le differenze.\n",
    "\n",
    "**Esercizio 1:** Studia la classe MultipleFisherDiscriminantAnalysis nel modulo FisherDA.py e completa il codice del metodo \"transform\".\n",
    "\n",
    "**Esercizio 2:** Completa il codice nelle celle seguenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unusual-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazione degli oggetti MultipleFisherDiscriminantAnalysis\n",
    "mda_3dim = ...  # Per la proiezione su 3 dimensioni\n",
    "mda_2dim = ...  # Per la proiezione su 2 dimensioni\n",
    "\n",
    "# Inizializzazione degli oggetti PrincipalComponentAnalysis\n",
    "pca_3dim = ...  # Per la proiezione su 3 dimensioni\n",
    "pca_2dim = ...  # Per la proiezione su 2 dimensioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coated-engagement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparazione dataset per i metodi \"fit\" di mda_1dim, mda_2dim, pca_1dim, pca_2dim.\n",
    "X = ...\n",
    "y = ...\n",
    "\n",
    "# \"Fit\" degli oggetti sopra inizializzati\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "artificial-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasformazione del dataset X rispetto alle proiezioni eseguite da mda_1dim, mda_2dim, pca_1dim, pca_2dim.\n",
    "# ATTENZIONE! usare StandardScaler per PCA!\n",
    "\n",
    "Z3m = ...  # Trasformazione rispetto mda_3dim\n",
    "Z2m = ...  # Trasformazione rispetto mda_2dim\n",
    "\n",
    "Z3p = ...  # Trasformazione rispetto pca_3dim\n",
    "Z2p = ...  # Trasformazione rispetto pca_2dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "parental-struggle",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a979a6176336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot a confronto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclass_colors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtab10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Plot per proiezione in R^2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Plot a confronto\n",
    "\n",
    "class_colors = [plt.cm.tab10.colors[c] for c in y]\n",
    "\n",
    "# Plot per proiezione in R^2\n",
    "fig2, axs2 = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axs2[0].scatter(..., ..., c=class_colors, alpha=0.15)\n",
    "axs2[0].set_title('MDA')\n",
    "axs2[1].scatter(..., ..., c=class_colors, alpha=0.15)\n",
    "axs2[1].set_title('PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recreational-produce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53ab18ce2b54bc9a410cc34d2055a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a7f7b7c4d1c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig_Z3m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0max_Z3m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig_Z3m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'3d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0max_Z3m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ3m\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ3m\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ3m\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_colors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MDA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ellipsis' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Plot a confronto\n",
    "\n",
    "# Plot per proiezione in R^3\n",
    "\n",
    "fig_Z3m = plt.figure(figsize=(10, 8))\n",
    "ax_Z3m = fig_Z3m.add_subplot(111, projection='3d')\n",
    "ax_Z3m.scatter(Z3m[:, 0], Z3m[:, 1], Z3m[:, 2], c=class_colors, alpha=0.15)\n",
    "plt.title('MDA')\n",
    "\n",
    "fig_Z3p = plt.figure(figsize=(10, 8))\n",
    "ax_Z3p = fig_Z3p.add_subplot(111, projection='3d')\n",
    "ax_Z3p.scatter(Z3p[:, 0], Z3p[:, 1], Z3p[:, 2], c=class_colors, alpha=0.15)\n",
    "plt.title('PCA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-agency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
